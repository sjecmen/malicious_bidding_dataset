{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "email_to_id = {}\n",
    "paper_to_id = {}\n",
    "HB = np.zeros((31, 28)) # (reviewers, papers) with entries in {-1, 0, 1}\n",
    "MB = np.zeros((31, 28)) # (reviewers, papers) with entries in {-1, 0, 1}\n",
    "\n",
    "reviewer_id = 0\n",
    "with open('unanonymize/malicious_bidding.csv') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    header = next(csv_reader)\n",
    "    assert(header[11] == 'RecipientEmail' and header[17] == 'Q3_1' and header[44] == 'Q3_28')\n",
    "    header = next(csv_reader)\n",
    "    for paper_id, paper in enumerate(header[17:45]):\n",
    "        paper_name = paper[paper.find(': -') + 3:].strip()\n",
    "        paper_to_id[paper_name] = paper_id\n",
    "    header = next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        email_to_id[row[11]] = reviewer_id\n",
    "        for paper_id in range(28):\n",
    "            if row[17 + paper_id] == 'Not willing to review':\n",
    "                MB[reviewer_id, paper_id] = -1\n",
    "            elif row[17 + paper_id] == 'Indifferent':\n",
    "                MB[reviewer_id, paper_id] = 0\n",
    "            elif row[17 + paper_id] == 'Eager to review':\n",
    "                MB[reviewer_id, paper_id] = 1\n",
    "        reviewer_id += 1\n",
    "\n",
    "with open('unanonymize/honest_bidding.csv') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    header = next(csv_reader)\n",
    "    assert(header[11] == 'RecipientEmail' and header[17] == 'Q3_1' and header[44] == 'Q3_28')\n",
    "    header = next(csv_reader)\n",
    "    header = next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        if row[11] not in email_to_id:\n",
    "            continue\n",
    "        reviewer_id = email_to_id[row[11]]\n",
    "        for paper_id in range(28):\n",
    "            if row[17 + paper_id] == 'Not willing to review':\n",
    "                HB[reviewer_id, paper_id] = -1\n",
    "            elif row[17 + paper_id] == 'Indifferent':\n",
    "                HB[reviewer_id, paper_id] = 0\n",
    "            elif row[17 + paper_id] == 'Eager to review':\n",
    "                HB[reviewer_id, paper_id] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_names = [\"Making Machine Learning Fair\",\n",
    "\"Interpreting AI Decision-Making\",\n",
    "\"Transparent Machine-Learning Models\",\n",
    "\"Voting for Participatory Budgeting\",\n",
    "\"Voting with Delegation\",\n",
    "\"Improved Learning from Rankings\",\n",
    "\"Equilibrium Selection in Cooperative Games\",\n",
    "\"Communication for Teamwork in Games\",\n",
    "\"Multi-Agent Cooperative Board Games\",\n",
    "\"An Overview of Zero-Sum Games\",\n",
    "\"Solution Concepts in Many-Player Games\",\n",
    "\"Stackelberg Security Games for Coastal Defense\",\n",
    "\"A No-Regret Algorithm for Efficient Equilibrium Computation\",\n",
    "\"Consistency of Bayesian Inference\",\n",
    "\"Fitting Graphical Models\",\n",
    "\"A Novel Gaussian Process Approximation\",\n",
    "\"A*+DFS: A Hybrid Search Algorithm\",\n",
    "\"A* Search Under Uncertainty\",\n",
    "\"Search-Based Planning of Robot Trajectories\",\n",
    "\"Online Convex Optimization with Regularization\",\n",
    "\"Private Stochastic Convex Optimization\",\n",
    "\"A Hybrid Method for Non-Convex Optimization\",\n",
    "\"Memory and Computation-Efficient Kernel SVMs\",\n",
    "\"Forecasting Stock Prices with Deep Learning\",\n",
    "\"A Deep Learning Approach for Anomaly Detection\",\n",
    "\"New Algorithms for 3D Computer Vision\",\n",
    "\"Towards More Accurate NLP Models\",\n",
    "\"Optimal Error Bounds in Statistical Learning Theory\"]\n",
    "\n",
    "reviewer_to_sas = {} # dict of review -> list of subject areas\n",
    "reviewer_to_group = {} # dict of reviewer -> group id\n",
    "reviewer_to_sa = {} # dict of review -> subject area of authored paper\n",
    "sa_to_paper_ids = {} # dict of subject area -> list of papers in the subject area\n",
    "paper_to_sa = {} # dict of paper -> subject area\n",
    "group_to_targets = {} # dict of group -> list of target papers\n",
    "\n",
    "SA = np.zeros(HB.shape) # (reviewers, papers) with entries in {0, 1}\n",
    "group_map = {} # dict of group id -> list of reviewer indices in that group\n",
    "author_map = {} # dict of reviewer -> index of paper authored\n",
    "target_map = {} # dict of reviewer -> index of target paper (for reviewers with group size 1)\n",
    "author_map_group = {} # dict of reviewer -> indices of target papers (including other team members' authored papers)\n",
    "\n",
    "with open('analysis/new_groups.csv') as csvfile:\n",
    "    r = csv.reader(csvfile)\n",
    "    header = next(r)\n",
    "    assert(all([x == y for x, y in \n",
    "        zip(header, ['name', 'sas', 'authored_sa', 'authored_id', 'target_sa', 'target_id', 'group'])\n",
    "        ]))\n",
    "    for row in r:\n",
    "        if row[0] in email_to_id:\n",
    "            reviewer_id = email_to_id[row[0]]\n",
    "        else:\n",
    "            reviewer_id = -1\n",
    "        \n",
    "        sas = [int(x) for x in row[1].strip().split(' ')]\n",
    "        if reviewer_id >= 0:\n",
    "            reviewer_to_sas[reviewer_id] = sas\n",
    "        \n",
    "        sa_id = int(row[2])\n",
    "        paper_id = paper_to_id[paper_names[int(row[3])]]\n",
    "        if reviewer_id >= 0:\n",
    "            reviewer_to_sa[reviewer_id] = sa_id\n",
    "            author_map[reviewer_id] = paper_id          \n",
    "        paper_to_sa[paper_id] = sa_id\n",
    "        if sa_id in sa_to_paper_ids:\n",
    "            sa_to_paper_ids[sa_id].append(paper_id)\n",
    "        else:\n",
    "            sa_to_paper_ids[sa_id] = [paper_id]\n",
    "        \n",
    "        if reviewer_id >= 0:\n",
    "            group = int(row[6])\n",
    "            if group in group_map:\n",
    "                group_map[group].append(reviewer_id)\n",
    "            else:\n",
    "                group_map[group] = [reviewer_id]\n",
    "            reviewer_to_group[reviewer_id] = group\n",
    "            if len(row[5]) > 0:\n",
    "                target_id = paper_to_id[paper_names[int(row[5])]]\n",
    "                target_map[reviewer_id] = target_id\n",
    "        \n",
    "        group = int(row[6])\n",
    "        if group in group_to_targets:\n",
    "            group_to_targets[group].append(paper_id)\n",
    "        else:\n",
    "            group_to_targets[group] = [paper_id]\n",
    "\n",
    "for reviewer_id in range(len(reviewer_to_sas)):\n",
    "    for sa_id in reviewer_to_sas[reviewer_id]:\n",
    "        for paper_id in sa_to_paper_ids[sa_id]:\n",
    "            SA[reviewer_id, paper_id] = 1\n",
    "\n",
    "for reviewer_id in range(len(reviewer_to_group)):\n",
    "    author_map_group[reviewer_id] = group_to_targets[reviewer_to_group[reviewer_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('analysis/Biddings.npy', 'wb') as f:\n",
    "    np.save(f, HB)\n",
    "    np.save(f, MB)\n",
    "    np.save(f, SA)\n",
    "\n",
    "with open('analysis/maps.pkl', 'wb') as f:\n",
    "    pickle.dump(author_map, f)\n",
    "    pickle.dump(group_map, f)\n",
    "    pickle.dump(target_map, f)\n",
    "    pickle.dump(author_map_group, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('analysis/Result.npy', 'rb') as f:\n",
    "    success_by_reviewer = np.load(f)\n",
    "    rank_by_reviewer_simple = np.load(f)\n",
    "    rank_by_reviewer_cluster = np.load(f)\n",
    "    rank_by_reviewer_row_rank = np.load(f)\n",
    "    diff_by_reviewer_hamming = np.load(f)\n",
    "    diff_by_reviewer_L1 = np.load(f)\n",
    "\n",
    "email_list = list(email_to_id.keys())\n",
    "reviewer_id_list = list(email_to_id.values())\n",
    "     \n",
    "with open('analysis/Result.csv', 'w', newline='') as csvfile:\n",
    "    column_names = ['Email', 'Group_id', 'Collaborators', 'Success_rate', 'Rank_simple', \\\n",
    "                   'Rank_cluster', 'Rank_low_rank', 'Diff_hamming', 'Diff_L1']\n",
    "    csv_writer = csv.DictWriter(csvfile, fieldnames=column_names)\n",
    "    csv_writer.writeheader()\n",
    "    for reviewer_idx in range(success_by_reviewer.shape[0]):\n",
    "        row = {}\n",
    "        row['Email'] = email_list[reviewer_id_list.index(reviewer_idx)]\n",
    "        row['Group_id'] = reviewer_to_group[reviewer_idx]\n",
    "        row['Collaborators'] = group_map[row['Group_id']]\n",
    "        row['Success_rate'] = success_by_reviewer[reviewer_idx]\n",
    "        row['Rank_simple'] = rank_by_reviewer_simple[reviewer_idx]\n",
    "        row['Rank_cluster'] = rank_by_reviewer_cluster[reviewer_idx]\n",
    "        row['Rank_low_rank'] = rank_by_reviewer_row_rank[reviewer_idx]\n",
    "        row['Diff_hamming'] = diff_by_reviewer_hamming[reviewer_idx]\n",
    "        row['Diff_L1'] = diff_by_reviewer_L1[reviewer_idx]\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(li_):\n",
    "    li = list(li_)\n",
    "    ctr = [0, 0, 0, 0, 0, 0, 0]\n",
    "    for x in li:\n",
    "        if 0 <= x < 2:\n",
    "            ctr[0] += 1\n",
    "        if 2 <= x < 5:\n",
    "            ctr[1] += 1\n",
    "        if 5 <= x < 9:\n",
    "            ctr[2] += 1\n",
    "        if 9 <= x < 13:\n",
    "            ctr[3] += 1\n",
    "        if 13 <= x < 15:\n",
    "            ctr[4] += 1\n",
    "        if 15 <= x < 19:\n",
    "            ctr[5] += 1\n",
    "        if 19 <= x < 25:\n",
    "            ctr[6] += 1\n",
    "    return ctr\n",
    "\n",
    "print(count(reviewer_to_sa.values()))\n",
    "print(count(paper_to_sa.values()))\n",
    "print(group_to_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taEV2",
   "language": "python",
   "name": "taev2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
